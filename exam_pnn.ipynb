{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "precision=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Augmentation(x):\n",
    "    return np.concatenate((np.ones((1,x.shape[1])),x),axis=0)\n",
    "\n",
    "def Normalization(x,labels):\n",
    "    x[:,labels!=1]=-x[:,labels!=1]\n",
    "    return x\n",
    "\n",
    "def eu_dis(x1,x2):\n",
    "    # 行向量\n",
    "    # 如果传进来的是一个数组与一个向量，数组放第一个参数 \n",
    "    return np.sum((x1-x2)**2,axis=1)**0.5 if x1.shape[0]>1 and len(x1.shape)>1 else np.sum((x1-x2)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear discriminant function\n",
    "# [w0 w1 w2]\n",
    "w=np.mat('-5 2 1')\n",
    "# 每一列是一个变量 第一行都是1，与w0相乘\n",
    "x=np.mat('1 1 1;1 2 3; 1 2 3')\n",
    "rst=w*x\n",
    "labels=np.sign(w*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quadratic g(x)=x^tAx+x^tb+c\n",
    "A=np.mat('2 1;1 4')\n",
    "b=np.mat('1;2')\n",
    "x=np.mat('0 1;-1 1')\n",
    "c=-3\n",
    "for i in range(x.shape[1]):\n",
    "    x_i=x[:,i]\n",
    "    g_x=x_i.T*A*x_i+x_i.T*b+c\n",
    "    print(g_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Perceptron Learning algorithm\n",
    "# Augenmented and Sample Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "y=np.mat('1 1 -1 -1;1 2 -4 -5;5 5 -1 -1')\n",
    "a=np.mat('-25;6;3')\n",
    "a_before=a\n",
    "lr=1\n",
    "for i in range(10):\n",
    "    g_x=a.T*y\n",
    "    for i in range(g_x.shape[1]):\n",
    "        if g_x[0,i]<=0:\n",
    "            a=a+lr*y[:,i] # 产生新对象，否则 a_before要用np.copy\n",
    "    print(\"gx:{0} a:{1}\".format(g_x[0,0],a.T))\n",
    "    if (a==a_before).all():break\n",
    "    a_before=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sequential Perceptron Learning algorithm\n",
    "# Augenmented and Sample Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "y=np.mat('1 2 4 5;5 5 1 1')\n",
    "labels=np.array([1,1,2,2])\n",
    "y=Augmentation(y)\n",
    "y=Normalization(y,labels)\n",
    "a=np.mat('-25;6;3')\n",
    "epoch=y.shape[1]\n",
    "lr=1\n",
    "label=[]\n",
    "for i in range(epoch*10):\n",
    "    j=i%epoch\n",
    "    x=y[:,j]\n",
    "    g_x=a.T*x\n",
    "    label.append(np.sign(g_x[0,0]))\n",
    "    if g_x[0,0]<0:\n",
    "        a+=lr*x # 产生新对象，否则 a_before要用np.copy\n",
    "    print(\"gx:{0} a:{1}\".format(g_x[0,0],a.T))\n",
    "    if j==epoch-1:\n",
    "        if (np.array(label)==1).all():break\n",
    "        else:label=[]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Perceptron Learning algorithm\n",
    "# Without Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "y=np.mat('0 1 2 -3 -2 -3;2 2 1 1 -1 -2')\n",
    "labels=np.array([1,1,1,-1,-1,-1])\n",
    "y=Augmentation(y)\n",
    "#y=Normalization(y,labels)\n",
    "a=np.mat('1;0;0')\n",
    "epoch=y.shape[1]\n",
    "lr=1\n",
    "label,label_b=[],[-2,-2,-2,-2,-2,-2]\n",
    "for i in range(epoch*10):\n",
    "    j=i%epoch\n",
    "    x=y[:,j]\n",
    "    g_x=a.T*x\n",
    "    label.append(np.sign(g_x[0,0]))\n",
    "    if label[j]!=labels[j]:\n",
    "        a+=lr*labels[j]*x # 产生新对象，否则 a_before要用np.copy\n",
    "    print(\"gx:{0} a:{1}\".format(g_x[0,0],a.T))\n",
    "    if j==epoch-1:\n",
    "        if (np.array(label)==labels).all() and (np.array(label)==np.array(label_b)).all() :break\n",
    "        else:\n",
    "            label_b=label.copy()\n",
    "            label=[]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Sequential Multiclass Perceptron Learning algorithm \n",
    "# Without Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "y=np.mat('1 2 0 -1 -1;1 0 2 1 -1')\n",
    "labels=np.array([1,1,2,2,3])\n",
    "y=Augmentation(y)\n",
    "#y=Normalization(y,labels)\n",
    "a=np.mat('0 0 0;0 0 0;0 0 0',dtype=np.float64)\n",
    "epoch=y.shape[1]\n",
    "lr=1\n",
    "label,label_b=[],[-2,-2,-2,-2,-2]\n",
    "for i in range(epoch*10):\n",
    "    j=i%epoch\n",
    "    x=y[:,j]\n",
    "    g_x=a.T*x\n",
    "    # g_x是一列\n",
    "    # i_max is tha class label, index should minus -1\n",
    "    i_max=max(np.argmax(g_x,axis=0)[0,0]+1,g_x.shape[0]-np.argmax(g_x[::-1],axis=0)[0,0])\n",
    "    label.append(i_max)\n",
    "    if label[j]!=labels[j]:\n",
    "        a[:,labels[j]-1]+=lr*x # 产生新对象，否则 a_before要用np.copy\n",
    "        a[:,i_max-1]-=lr*x\n",
    "    print(\"gx:{0} \\n a:a{1}\".format(g_x.T,a.T))\n",
    "    if j==epoch-1:\n",
    "        if (np.array(label)==labels).all() and (np.array(label)==np.array(label_b)).all() :break\n",
    "        else:\n",
    "            label_b=label.copy()\n",
    "            label=[]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE via Pseudoinverse\n",
    "x=np.mat('0,1,2,-3,-2,-3;2 2 1 1 -1 -2')\n",
    "labels=np.array([1,1,1,-1,-1,-1])\n",
    "y=Augmentation(x)\n",
    "y=Normalization(y,labels)\n",
    "b=np.mat('1;1;1;1;1;1')\n",
    "y_r=linalg.pinv(y.T)\n",
    "a=y_r*b\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Widrow-Hoff Learning Algorithm\n",
    "# Using Augmentation and Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "y=np.mat('0 1 2 -3 -2 -3;2 2 1 1 -1 -2')\n",
    "labels=np.array([1,1,1,-1,-1,-1])\n",
    "y=Augmentation(y)\n",
    "y=Normalization(y,labels)\n",
    "a=np.mat('1;0;0',dtype=np.float64)\n",
    "b=np.array([1,1,1,1,1,1])\n",
    "b=b.reshape(b.shape[0],1)\n",
    "epoch=y.shape[1]\n",
    "lr=0.1\n",
    "a_old=a.copy()\n",
    "# for i in range(k):\n",
    "for i in range(epoch*2):\n",
    "    j=i%epoch\n",
    "    x=y[:,j]\n",
    "    g_x=a.T*x\n",
    "    a+=np.multiply(lr*(b[j]-g_x[0,0]),x) # 产生新对象，否则 a_before要用np.copy\n",
    "    print(\"a_old:{0} y:{1} gx:{2} a:{3}\".format(np.round(a_old.T,precision),x.T,round(g_x[0,0],precision),\n",
    "                                                np.round(a.T,precision)))\n",
    "    a_old=np.copy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-nearest-neighbour classifier\n",
    "# 每个样本一行，行向量\n",
    "fv=np.array([\n",
    "    [0.15,0.35],\n",
    "    [0.15,0.28],\n",
    "    [0.12,0.2],\n",
    "    [0.1,0.32],\n",
    "    [0.06,0.25]\n",
    "])\n",
    "sample=np.array([0.1,0.25])\n",
    "labels=np.array([1,2,2,3,3])\n",
    "# fv 放第一个参数\n",
    "dis=eu_dis(fv,sample)\n",
    "print(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sequential Delta learning rule with H linear threshold\n",
    "# Without Augmentation and Normalization\n",
    "# Widrow-Hoff Learning Algorithm\n",
    "# Using Augmentation and Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "y=np.mat('0 1 2 -3 -2 -3;2 2 1 1 -1 -2')\n",
    "labels=np.array([1,1,1,0,0,0])\n",
    "y=Augmentation(y)\n",
    "#y=Normalization(y,labels)\n",
    "a=np.mat('1;0;0',dtype=np.float64)\n",
    "t=np.array([1,1,1,0,0,0])\n",
    "t=t.reshape(t.shape[0],1)\n",
    "epoch=y.shape[1]\n",
    "lr=1\n",
    "a_old=np.copy(a)\n",
    "label,label_b=[],[-2,-2,-2,-2,-2]\n",
    "# for i in range(k):\n",
    "for i in range(epoch*10):\n",
    "    j=i%epoch\n",
    "    x=y[:,j]\n",
    "    g_x=a.T*x\n",
    "    y_=1 if g_x[0,0]>0 else 0\n",
    "    label.append(y_)\n",
    "    temp=lr*np.multiply(t[j]-y_,x)\n",
    "    a+=temp # 产生新对象，否则 a_before要用np.copy\n",
    "    print(\"x:{0} t:{1} y:{2} t-y:{3} temp:{4} w:{5}\".format(np.round(x.T,precision),t[j][0],y_,t[j][0]-y_,\n",
    "                                                    np.round(temp.T,precision),np.round(a.T,precision)))\n",
    "    a_old=np.copy(a)\n",
    "    if j==epoch-1:\n",
    "        if (np.array(label)==labels).all() and (np.array(label)==np.array(label_b)).all() :break\n",
    "        else:\n",
    "            label_b=label.copy()\n",
    "            label=[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Delta learning rule with H linear threshold\n",
    "# Without Augmentation and Normalization\n",
    "# Widrow-Hoff Learning Algorithm\n",
    "# Using Augmentation and Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "y=np.mat('0 1 2 -3 -2 -3;2 2 1 1 -1 -2')\n",
    "labels=np.array([1,1,1,0,0,0])\n",
    "y=Augmentation(y)\n",
    "#y=Normalization(y,labels)\n",
    "a=np.mat('1;0;0',dtype=np.float64)\n",
    "t=np.array([1,1,1,0,0,0])\n",
    "epoch=y.shape[1]\n",
    "lr=1\n",
    "a_old=np.copy(a)\n",
    "label,label_b=[],[-2,-2,-2,-2,-2]\n",
    "# for i in range(k):\n",
    "for i in range(10):\n",
    "    g_x=a.T*y\n",
    "    # g_x 是列向量\n",
    "    y_=np.array([1 if g_x[0,i]>0 else 0 for i in range(g_x.shape[1])],dtype=np.int64)\n",
    "    temp=lr*np.multiply(t-y_,y)\n",
    "    a+=temp.sum(axis=1)\n",
    "    # 注意，这里都是用的列向量，原算法x转置，w不转置\n",
    "    # 输出已变成行向量\n",
    "    print(\"x:{0} t:{1} y:{2} t-y:{3} temp:{4} w:{5}\".format(np.round(y.T,precision),t.T,y_.T,(t-y_).T,\n",
    "                                                    np.round(temp.T,precision),np.round(a.T,precision)))\n",
    "    if (a==a_old).all():break\n",
    "    a_old=np.copy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative feedback network\n",
    "# Without Augmentation and Normalization\n",
    "# Widrow-Hoff Learning Algorithm\n",
    "# Using Augmentation and Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "x=np.mat('1;1;0')\n",
    "y=np.mat('0;0',dtype=np.float64)\n",
    "#labels=np.array([1,1,1,0,0,0])\n",
    "#y=Augmentation(y)\n",
    "#y=Normalization(y,labels)\n",
    "W=np.mat('1 1 0;1 1 1',dtype=np.float64)\n",
    "lr=0.5\n",
    "# for i in range(k):\n",
    "for i in range(5):\n",
    "    e=x-W.T*y\n",
    "    temp1=W*e\n",
    "    y+=lr*temp1\n",
    "    temp2=W.T*y #注意这个wy是更新完y之后的\n",
    "    print(\"e:{0} We:{1} y:{2} Wy:{3}\".format(np.round(e.T,precision),np.round(temp1.T,precision),\n",
    "                                                             np.round(y.T,precision),np.round(temp2.T,precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regulatory Feedback or Divisive Input Modulation.\n",
    "x=np.mat('1;1;0')\n",
    "y=np.mat('0;0',dtype=np.float64)\n",
    "#labels=np.array([1,1,1,0,0,0])\n",
    "#y=Augmentation(y)\n",
    "#y=Normalization(y,labels)\n",
    "W=np.mat('1 1 0;1 1 1',dtype=np.float64)\n",
    "W_Norm=np.divide(W,W.sum(axis=1))\n",
    "e1,e2=0.01,0.01\n",
    "# for i in range(k):\n",
    "for i in range(5):\n",
    "    temp1=W.T*y\n",
    "    temp1[temp1<e2]=e2\n",
    "    e=np.divide(x,temp1)\n",
    "    temp2=W_Norm*e\n",
    "    y[y<e1]=e1\n",
    "    y=np.multiply(y,temp2)\n",
    "    temp3=W.T*y #注意这个wy是更新完y之后的\n",
    "    print(\"e:{0} W_Ne:{1} y:{2} Wy:{3}\".format(np.round(e.T,precision),np.round(temp2.T,precision),\n",
    "                                                             np.round(y.T,precision),np.round(temp3.T,precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fisher’s method\n",
    "# compare two weight which is better\n",
    "d1=np.array([\n",
    "    [1,2],\n",
    "    [2,1],\n",
    "    [3,3],\n",
    "])\n",
    "d2=np.array([\n",
    "    [6,5],\n",
    "    [7,8]\n",
    "])\n",
    "# 注意np.dot()\n",
    "w1=np.array([-1,5])\n",
    "w2=np.array([2,-3])\n",
    "w1=w1.reshape(1,w1.shape[0])\n",
    "w2=w2.reshape(1,w2.shape[0])\n",
    "m1=d1.mean(axis=0)\n",
    "m2=d2.mean(axis=0)\n",
    "sb1=np.sum(np.dot(w1,(m1-m2).reshape(m1.shape[0],1))**2)\n",
    "sw1=sum([np.sum(w1.dot((x-m1).reshape(m1.shape[0],1))**2) for x in d1])\n",
    "sw1+=sum([np.sum(w1.dot((x-m2).reshape(m2.shape[0],1))**2) for x in d2])\n",
    "J1=sb1/sw1\n",
    "sb2=np.sum(np.dot(w2,(m1-m2).reshape(m1.shape[0],1))**2)\n",
    "sw2=sum([np.sum(w2.dot((x-m1).reshape(m1.shape[0],1))**2) for x in d1])\n",
    "sw2+=sum([np.sum(w2.dot((x-m2).reshape(m2.shape[0],1))**2) for x in d2])\n",
    "J2=sb2/sw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extreme Learning Machines\n",
    "x=np.mat('0 0 1 1;0 1 0 1')\n",
    "x=Augmentation(x)\n",
    "V=np.mat('-0.62 0.44 -0.91;-0.81 -0.09 0.02;0.74 -0.91 -0.60;'\n",
    "         +'-0.82 -0.92 0.71;-0.26 0.68 0.15;0.80 -0.94 -0.83')\n",
    "w=np.mat('0,0,0,-1,0,0,2')\n",
    "Y=V*x       \n",
    "Y[Y<0]=0\n",
    "Y[Y>0]=1\n",
    "Y=Augmentation(Y)\n",
    "z=w*Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse Coding\n",
    "# y是列向量\n",
    "y1=np.mat('1;0;0;0;1;0;0;0')\n",
    "y2=np.mat('0;0;1;0;0;0;-1;0')\n",
    "V=np.mat('0.4 -0.6;0.55 -0.45;0.5 -0.5;-0.1 0.9;-0.5 -0.5;0.9 0.1;0.5 0.5;0.45 0.55')\n",
    "x=np.mat('-0.05;-0.95')\n",
    "x1_=V.T*y1\n",
    "x2_=V.T*y2\n",
    "e1=np.multiply(x1_-x,x1_-x).sum()**0.5\n",
    "e2=np.multiply(x2_-x,x2_-x).sum()**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singular Value Decomposition\n",
    "A=np.mat(\"5 3 0;3 5 0;0 0 0\")\n",
    "u,sigma,vt = linalg.svd(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 硬编码\n",
    "# SVM\n",
    "# 向量需要增强\n",
    "# \n",
    "# w0 w1 w2\n",
    "sv=np.array([\n",
    "    [1,5,1],\n",
    "    [1,5,-1],\n",
    "    [1,3,0],\n",
    "])\n",
    "labels=[1,1,-1]\n",
    "b=np.mat('1;1;1')\n",
    "A=np.array([\n",
    "    labels[0]*sv[0],\n",
    "    labels[1]*sv[1],\n",
    "    labels[2]*sv[2],\n",
    "])\n",
    "A=np.mat(A)\n",
    "w = linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive Boost\n",
    "w=np.array([0.5,0.5])\n",
    "y=np.array([1,-1])\n",
    "h1=np.array([-1,1])\n",
    "error=0.4\n",
    "af[i]=np.log((1-error)/error)\n",
    "w=[w[i]*pow(np.e,-af*y[i]*h1[i]) for i in range(len(h1))]\n",
    "w=w/sum(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Oja's learning rule\n",
    "# Without Augmentation and Normalization\n",
    "# Widrow-Hoff Learning Algorithm\n",
    "# Using Augmentation and Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "x_s=np.mat('-5 -2 0 0 3 4;-4 0 -1 1 2 2')\n",
    "#y=Augmentation(y)\n",
    "#y=Normalization(y,labels)\n",
    "w=np.mat('-1 0',dtype=np.float64)\n",
    "epoch=x_s.shape[1]\n",
    "lr=0.01\n",
    "# for i in range(k):\n",
    "for i in range(epoch*2):\n",
    "    print(\"Epoch {0}\".format(i+1))\n",
    "    w_sum=0\n",
    "    for j in range(epoch):\n",
    "        t=j%epoch\n",
    "        x=x_s[:,t]\n",
    "        y=w*x\n",
    "        temp1=x.T-np.multiply(y[0,0],w)\n",
    "        temp2=lr*np.multiply(y[0,0],temp1)\n",
    "        w_sum+=temp2\n",
    "        print(\"x:{0} y:{1} xt-yw:{2} lr*3:{3}\".format(np.round(x.T,precision),y[0,0],\n",
    "                                                            np.round(temp1,precision),np.round(temp2,precision)))\n",
    "    w+=w_sum\n",
    "    print(\"totoa change:{0} w:{1}\".format(np.round(w_sum,precision),np.round(w,precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=np.mat('-1;5')\n",
    "w2=np.mat('2;-3')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
