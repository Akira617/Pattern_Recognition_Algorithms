{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "precision=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Augmentation(x):\n",
    "    return np.concatenate((np.ones((1,x.shape[1])),x),axis=0)\n",
    "\n",
    "def Normalization(x,labels):\n",
    "    x[:,labels!=1]=-x[:,labels!=1]\n",
    "    return x\n",
    "\n",
    "def eu_dis(x1,x2):\n",
    "    # 行向量\n",
    "    # 如果传进来的是一个数组与一个向量，数组放第一个参数 \n",
    "    return np.sum((x1-x2)**2,axis=1)**0.5 if x1.shape[0]>1 and len(x1.shape)>1 else np.sum((x1-x2)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear discriminant function\n",
    "# [w0 w1 w2]\n",
    "w=np.mat('-5 2 1')\n",
    "# 每一列是一个变量 第一行都是1，与w0相乘\n",
    "x=np.mat('1 1 1;1 2 3; 1 2 3')\n",
    "rst=w*x\n",
    "labels=np.sign(w*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quadratic g(x)=x^tAx+x^tb+c\n",
    "A=np.mat('2 1;1 4')\n",
    "b=np.mat('1;2')\n",
    "x=np.mat('0 1;-1 1')\n",
    "c=-3\n",
    "for i in range(x.shape[1]):\n",
    "    x_i=x[:,i]\n",
    "    g_x=x_i.T*A*x_i+x_i.T*b+c\n",
    "    print(g_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Perceptron Learning algorithm\n",
    "# Augenmented and Sample Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "y=np.mat('1 1 -1 -1;1 2 -4 -5;5 5 -1 -1')\n",
    "a=np.mat('-25;6;3')\n",
    "a_before=a\n",
    "lr=1\n",
    "for i in range(10):\n",
    "    g_x=a.T*y\n",
    "    for i in range(g_x.shape[1]):\n",
    "        if g_x[0,i]<=0:\n",
    "            a=a+lr*y[:,i] # 产生新对象，否则 a_before要用np.copy\n",
    "    print(\"gx:{0} a:{1}\".format(g_x[0,0],a.T))\n",
    "    if (a==a_before).all():break\n",
    "    a_before=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sequential Perceptron Learning algorithm\n",
    "# Augenmented and Sample Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "y=np.mat('1 2 4 5;5 5 1 1')\n",
    "labels=np.array([1,1,2,2])\n",
    "y=Augmentation(y)\n",
    "y=Normalization(y,labels)\n",
    "a=np.mat('-25;6;3')\n",
    "epoch=y.shape[1]\n",
    "lr=1\n",
    "label=[]\n",
    "for i in range(epoch*10):\n",
    "    j=i%epoch\n",
    "    x=y[:,j]\n",
    "    g_x=a.T*x\n",
    "    label.append(np.sign(g_x[0,0]))\n",
    "    if g_x[0,0]<0:\n",
    "        a+=lr*x # 产生新对象，否则 a_before要用np.copy\n",
    "    print(\"gx:{0} a:{1}\".format(g_x[0,0],a.T))\n",
    "    if j==epoch-1:\n",
    "        if (np.array(label)==1).all():break\n",
    "        else:label=[]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Perceptron Learning algorithm\n",
    "# Without Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "y=np.mat('0 1 2 -3 -2 -3;2 2 1 1 -1 -2')\n",
    "labels=np.array([1,1,1,-1,-1,-1])\n",
    "y=Augmentation(y)\n",
    "#y=Normalization(y,labels)\n",
    "a=np.mat('1;0;0')\n",
    "epoch=y.shape[1]\n",
    "lr=1\n",
    "label,label_b=[],[-2,-2,-2,-2,-2,-2]\n",
    "for i in range(epoch*10):\n",
    "    j=i%epoch\n",
    "    x=y[:,j]\n",
    "    g_x=a.T*x\n",
    "    label.append(np.sign(g_x[0,0]))\n",
    "    if label[j]!=labels[j]:\n",
    "        a+=lr*labels[j]*x # 产生新对象，否则 a_before要用np.copy\n",
    "    print(\"gx:{0} a:{1}\".format(g_x[0,0],a.T))\n",
    "    if j==epoch-1:\n",
    "        if (np.array(label)==labels).all() and (np.array(label)==np.array(label_b)).all() :break\n",
    "        else:\n",
    "            label_b=label.copy()\n",
    "            label=[]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Sequential Multiclass Perceptron Learning algorithm \n",
    "# Without Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "y=np.mat('1 2 0 -1 -1;1 0 2 1 -1')\n",
    "labels=np.array([1,1,2,2,3])\n",
    "y=Augmentation(y)\n",
    "#y=Normalization(y,labels)\n",
    "a=np.mat('0 0 0;0 0 0;0 0 0',dtype=np.float64)\n",
    "epoch=y.shape[1]\n",
    "lr=1\n",
    "label,label_b=[],[-2,-2,-2,-2,-2]\n",
    "for i in range(epoch*10):\n",
    "    j=i%epoch\n",
    "    x=y[:,j]\n",
    "    g_x=a.T*x\n",
    "    # g_x是一列\n",
    "    # i_max is tha class label, index should minus -1\n",
    "    i_max=max(np.argmax(g_x,axis=0)[0,0]+1,g_x.shape[0]-np.argmax(g_x[::-1],axis=0)[0,0])\n",
    "    label.append(i_max)\n",
    "    if label[j]!=labels[j]:\n",
    "        a[:,labels[j]-1]+=lr*x # 产生新对象，否则 a_before要用np.copy\n",
    "        a[:,i_max-1]-=lr*x\n",
    "    print(\"gx:{0} \\n a:a{1}\".format(g_x.T,a.T))\n",
    "    if j==epoch-1:\n",
    "        if (np.array(label)==labels).all() and (np.array(label)==np.array(label_b)).all() :break\n",
    "        else:\n",
    "            label_b=label.copy()\n",
    "            label=[]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE via Pseudoinverse\n",
    "x=np.mat('0,1,2,-3,-2,-3;2 2 1 1 -1 -2')\n",
    "labels=np.array([1,1,1,-1,-1,-1])\n",
    "y=Augmentation(x)\n",
    "y=Normalization(y,labels)\n",
    "b=np.mat('1;1;1;1;1;1')\n",
    "y_r=linalg.pinv(y.T)\n",
    "a=y_r*b\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Widrow-Hoff Learning Algorithm\n",
    "# Using Augmentation and Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "y=np.mat('0 1 2 -3 -2 -3;2 2 1 1 -1 -2')\n",
    "labels=np.array([1,1,1,-1,-1,-1])\n",
    "y=Augmentation(y)\n",
    "y=Normalization(y,labels)\n",
    "a=np.mat('1;0;0',dtype=np.float64)\n",
    "b=np.array([1,1,1,1,1,1])\n",
    "b=b.reshape(b.shape[0],1)\n",
    "epoch=y.shape[1]\n",
    "lr=0.1\n",
    "a_old=a.copy()\n",
    "# for i in range(k):\n",
    "for i in range(epoch*2):\n",
    "    j=i%epoch\n",
    "    x=y[:,j]\n",
    "    g_x=a.T*x\n",
    "    a+=np.multiply(lr*(b[j]-g_x[0,0]),x) # 产生新对象，否则 a_before要用np.copy\n",
    "    print(\"a_old:{0} y:{1} gx:{2} a:{3}\".format(np.round(a_old.T,precision),x.T,round(g_x[0,0],precision),\n",
    "                                                np.round(a.T,precision)))\n",
    "    a_old=np.copy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-nearest-neighbour classifier\n",
    "# 每个样本一行，行向量\n",
    "fv=np.array([\n",
    "    [0.15,0.35],\n",
    "    [0.15,0.28],\n",
    "    [0.12,0.2],\n",
    "    [0.1,0.32],\n",
    "    [0.06,0.25]\n",
    "])\n",
    "sample=np.array([0.1,0.25])\n",
    "labels=np.array([1,2,2,3,3])\n",
    "# fv 放第一个参数\n",
    "dis=eu_dis(fv,sample)\n",
    "print(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sequential Delta learning rule with H linear threshold\n",
    "# Without Augmentation and Normalization\n",
    "# Widrow-Hoff Learning Algorithm\n",
    "# Using Augmentation and Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "y=np.mat('0 1 2 -3 -2 -3;2 2 1 1 -1 -2')\n",
    "labels=np.array([1,1,1,0,0,0])\n",
    "y=Augmentation(y)\n",
    "#y=Normalization(y,labels)\n",
    "a=np.mat('1;0;0',dtype=np.float64)\n",
    "t=np.array([1,1,1,0,0,0])\n",
    "t=t.reshape(t.shape[0],1)\n",
    "epoch=y.shape[1]\n",
    "lr=1\n",
    "a_old=np.copy(a)\n",
    "label,label_b=[],[-2,-2,-2,-2,-2]\n",
    "# for i in range(k):\n",
    "for i in range(epoch*10):\n",
    "    j=i%epoch\n",
    "    x=y[:,j]\n",
    "    g_x=a.T*x\n",
    "    y_=1 if g_x[0,0]>0 else 0\n",
    "    label.append(y_)\n",
    "    temp=lr*np.multiply(t[j]-y_,x)\n",
    "    a+=temp # 产生新对象，否则 a_before要用np.copy\n",
    "    print(\"x:{0} t:{1} y:{2} t-y:{3} temp:{4} w:{5}\".format(np.round(x.T,precision),t[j][0],y_,t[j][0]-y_,\n",
    "                                                    np.round(temp.T,precision),np.round(a.T,precision)))\n",
    "    a_old=np.copy(a)\n",
    "    if j==epoch-1:\n",
    "        if (np.array(label)==labels).all() and (np.array(label)==np.array(label_b)).all() :break\n",
    "        else:\n",
    "            label_b=label.copy()\n",
    "            label=[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Delta learning rule with H linear threshold\n",
    "# Without Augmentation and Normalization\n",
    "# Widrow-Hoff Learning Algorithm\n",
    "# Using Augmentation and Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "y=np.mat('0 1 2 -3 -2 -3;2 2 1 1 -1 -2')\n",
    "labels=np.array([1,1,1,0,0,0])\n",
    "y=Augmentation(y)\n",
    "#y=Normalization(y,labels)\n",
    "a=np.mat('1;0;0',dtype=np.float64)\n",
    "t=np.array([1,1,1,0,0,0])\n",
    "epoch=y.shape[1]\n",
    "lr=1\n",
    "a_old=np.copy(a)\n",
    "label,label_b=[],[-2,-2,-2,-2,-2]\n",
    "# for i in range(k):\n",
    "for i in range(10):\n",
    "    g_x=a.T*y\n",
    "    # g_x 是列向量\n",
    "    y_=np.array([1 if g_x[0,i]>0 else 0 for i in range(g_x.shape[1])],dtype=np.int64)\n",
    "    temp=lr*np.multiply(t-y_,y)\n",
    "    a+=temp.sum(axis=1)\n",
    "    # 注意，这里都是用的列向量，原算法x转置，w不转置\n",
    "    # 输出已变成行向量\n",
    "    print(\"x:{0} t:{1} y:{2} t-y:{3} temp:{4} w:{5}\".format(np.round(y.T,precision),t.T,y_.T,(t-y_).T,\n",
    "                                                    np.round(temp.T,precision),np.round(a.T,precision)))\n",
    "    if (a==a_old).all():break\n",
    "    a_old=np.copy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:[[1. 1. 0.]] We:[[2. 2.]] y:[[1. 1.]] Wy:[[2. 2. 1.]]\n",
      "e:[[-1. -1. -1.]] We:[[-2. -3.]] y:[[ 0.  -0.5]] Wy:[[-0.5 -0.5 -0.5]]\n",
      "e:[[1.5 1.5 0.5]] We:[[3.  3.5]] y:[[1.5  1.25]] Wy:[[2.75 2.75 1.25]]\n",
      "e:[[-1.75 -1.75 -1.25]] We:[[-3.5  -4.75]] y:[[-0.25  -1.125]] Wy:[[-1.375 -1.375 -1.125]]\n",
      "e:[[2.375 2.375 1.125]] We:[[4.75  5.875]] y:[[2.125  1.8125]] Wy:[[3.9375 3.9375 1.8125]]\n"
     ]
    }
   ],
   "source": [
    "# negative feedback network\n",
    "# Without Augmentation and Normalization\n",
    "# Widrow-Hoff Learning Algorithm\n",
    "# Using Augmentation and Normalization\n",
    "# axis=0 沿着行的方向求和，结果是列的和\n",
    "x=np.mat('1;1;0')\n",
    "y=np.mat('0;0',dtype=np.float64)\n",
    "#labels=np.array([1,1,1,0,0,0])\n",
    "#y=Augmentation(y)\n",
    "#y=Normalization(y,labels)\n",
    "W=np.mat('1 1 0;1 1 1',dtype=np.float64)\n",
    "lr=0.5\n",
    "# for i in range(k):\n",
    "for i in range(5):\n",
    "    e=x-W.T*y\n",
    "    temp1=W*e\n",
    "    y+=lr*temp1\n",
    "    temp2=W.T*y #注意这个wy是更新完y之后的\n",
    "    print(\"e:{0} We:{1} y:{2} Wy:{3}\".format(np.round(e.T,precision),np.round(temp1.T,precision),\n",
    "                                                             np.round(y.T,precision),np.round(temp2.T,precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:[[100. 100.   0.]] W_Ne:[[100.      66.6667]] y:[[1.     0.6667]] Wy:[[1.6667 1.6667 0.6667]]\n",
      "e:[[0.6 0.6 0. ]] W_Ne:[[0.6 0.4]] y:[[0.6    0.2667]] Wy:[[0.8667 0.8667 0.2667]]\n",
      "e:[[1.1538 1.1538 0.    ]] W_Ne:[[1.1538 0.7692]] y:[[0.6923 0.2051]] Wy:[[0.8974 0.8974 0.2051]]\n",
      "e:[[1.1143 1.1143 0.    ]] W_Ne:[[1.1143 0.7429]] y:[[0.7714 0.1524]] Wy:[[0.9238 0.9238 0.1524]]\n",
      "e:[[1.0825 1.0825 0.    ]] W_Ne:[[1.0825 0.7216]] y:[[0.8351 0.11  ]] Wy:[[0.945 0.945 0.11 ]]\n"
     ]
    }
   ],
   "source": [
    "# Regulatory Feedback or Divisive Input Modulation.\n",
    "x=np.mat('1;1;0')\n",
    "y=np.mat('0;0',dtype=np.float64)\n",
    "#labels=np.array([1,1,1,0,0,0])\n",
    "#y=Augmentation(y)\n",
    "#y=Normalization(y,labels)\n",
    "W=np.mat('1 1 0;1 1 1',dtype=np.float64)\n",
    "W_Norm=np.divide(W,W.sum(axis=1))\n",
    "e1,e2=0.01,0.01\n",
    "# for i in range(k):\n",
    "for i in range(5):\n",
    "    temp1=W.T*y\n",
    "    temp1[temp1<e2]=e2\n",
    "    e=np.divide(x,temp1)\n",
    "    temp2=W_Norm*e\n",
    "    y[y<e1]=e1\n",
    "    y=np.multiply(y,temp2)\n",
    "    temp3=W.T*y #注意这个wy是更新完y之后的\n",
    "    print(\"e:{0} W_Ne:{1} y:{2} Wy:{3}\".format(np.round(e.T,precision),np.round(temp2.T,precision),\n",
    "                                                             np.round(y.T,precision),np.round(temp3.T,precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA\n",
    "d1=np.array([\n",
    "    [1,1],\n",
    "    [1,2],\n",
    "    [1,3],\n",
    "    [2,4]\n",
    "])\n",
    "d2=np.array([\n",
    "    [1,5],\n",
    "    [1,1],\n",
    "    [1,6],\n",
    "    [2,2]\n",
    "])\n",
    "# 注意np.dot()\n",
    "w=np.array([2,3])\n",
    "w=w.reshape(w.shape[0],1)\n",
    "m1=d1.mean(axis=0)\n",
    "m2=d2.mean(axis=0)\n",
    "sb=np.sum(np.dot(w,(m1-m2).reshape(1,m1.shape[0]))**2)\n",
    "sw=sum([np.sum(w.dot((x-m1).reshape(1,m1.shape[0]))**2) for x in d1])\n",
    "sw+=sum([np.sum(w.dot((x-m2).reshape(1,m2.shape[0]))**2) for x in d2])\n",
    "J=sb/sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0425531914893617"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extreme Learning Machines\n",
    "V=np.mat()\n",
    "T=np.mat()\n",
    "x=np.mat()\n",
    "w=np.mat()\n",
    "Y=g(V*X) # Y is for all output\n",
    "z=w*y\n",
    "Y_r=linalg.pinv(Y)\n",
    "w=T*Y_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse Coding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singular Value Decomposition\n",
    "A=np.mat(\"5 3 0;3 5 0;0 0 0\")\n",
    "u,sigma,vt = linalg.svd(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.70710678, -0.70710678, -0.        ],\n",
       "        [-0.70710678,  0.70710678,  0.        ],\n",
       "        [ 0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.70710678, -0.70710678,  0.        ],\n",
       "        [-0.70710678,  0.70710678,  0.        ],\n",
       "        [ 0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
